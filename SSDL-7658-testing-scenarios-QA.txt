1. Project setup screen
    1) All main tables of that domain should be visible, specially OPS_MAIN.
    2) Add main table
    3) Edit OPS_MAIN table
    4) Enable new columns
    5) Sorting
    6) Filtering
    7) Pagination
    8) Basic Columns checkbox
    9) Mandatory selected columns - user should not be able to de-select them.
    10) unable to de-select saved columns
    11) Unseelected columns at the beginning of the table and saved/default selected columns at the end of the table.
2. Basic details
    Before save:
    1) See all main tables
    2) Changing a main table and verify loader is appearing to fetch the columns.
    3) If a main table has float and date columns then they should be available in Spend field and Date field dropdowns in Basic Details.
    After save:
    1) Main table dropdown should be disabled if at least one setting exist in the backend between consolidation to publish.
    2) 
3. Workflow scope:
    Existing behavior on Prod:
    1. User can see all main table columns in all configuration screens of Consolidation, excluding un-used Custom columns.
    2. Once user configures consolidation and runs it,
        then user only sees columns that have been ran as "Active column" in from Profile to Publish and Import/Export.

    New behavior as per SSDL-7658
    Configuration:
    1) Configure a one-time job from Load to Publish with New Load Data
    2) Configure a one-time job from Load to Publish with Historical
    3) Configure a one-time job from Load to Publish with Historical + New load data
    4) From Consolidation to Publish - if user has not selected a main table in basic details
        then upon clicking Configure button of any step, they should see a message saying Please select a main table to configure steps.
    5) Custom columns
        5.1) Test by adding custom columns from following screens.
        5.2) Added columns should be visible while configuring any job or Import/export as well as project setup.
    
    Running a job
    1) Using Stop After Every Stage
        1.1) Run Consolidation with a fresh new main table added from Project setup
            - You should see a message that table schema is changed.
        1.2) re-run Consolidation in the same job by adding a new column to same main table via Project Setup.
            - You should see a message that table schema is changed.
        1.3) Run Consolidation for a fresh new main table then run Profile by adding a new column to same main table.
    2) Run a job by adding custom columns.
        Available screens for custom columns:
        2.2) Consolidation - Moving to main table
        2.3) Consolidation - Master based normalization
        2.4) Publish - 4 screens
            a) Standard - Range bucket
            b) Standard - one/time flag
            c) Standard - old/new
            d) Standard - one to many
    3) Running two jobs with multi main table
        3.1) User should be able to run a job with one main table
            and if that job is in paused or stopped or not started status
            then user should be able to run another job with a different main table.
4. Job cloning
    1) While cloning a job, the main table dropdown should be disabled.
        That means user won't be able to change the main table for a new copy.
5. Import/export
    1) Run an import request for a main table
    2) Run an export request for a main table
6. Consolidation - Master Based Normalization
    In MBN, when you save a task then this task becomes a Reference Master table on UI as well as ADB.
    1) In a workflow job, configure Master Based Normalization with at least one task.
        1.1) In the database on .NET side, there should be one entry for your task in SSDL.SPEND_SSDL_Table sql table
            and the BaseTableId should be the ID of the Main table you selected in Basic Details section on UI.
        1.3) A Reference Master table's name must be unique for a main table. It means you can't create a Reference Master table in two jobs with two different main tables.
            If main table is same in two jobs then you can create the Reference Master table with same name in both jobs.
            1.3.1) If the selected main table is Main1 and you create a task by adding some columns and filters in Master Based Normalization in one job.
                Then a) In a new job, if you select Main1, and add a task in MBN with same name as task from previous job but this time select different columns and filters.
                    Then when you save the task, go back to the previous job and you should see the latest columns and filters.
                    b) In a new job, if you select Main2, and add a task in MBN with same name, then it should stop you from saving
                saying "a Reference Master table already exists with same name and Main1 main table as its base".
    2) Click on Generate master for a Reference master table created using a new main table and check if Table is generated successfully or it fails.
    3) In a different job, create a task in MBN but don't click on Generate button, just run that consolidation job and this time also, Reference Master table should be generated.
        Verify with ADB if Reference master table with that task's name is created or not.
7. Publish - 4 screens
    Currently: All 4 steps that are named as "Standard" behave like this on Prod.
        User can only see un-used columns on these 4 screens.
    After SSDL-7658:
        User can see all the columns that are selected and saved in Project Setup.
8. Clustering columns in Project Setup:
    Two sections: Supplier clustering and Classification clustering.
    Until PMG comes up with an enhancement story,
        1) With SSDL-7658, the VNE and Classify will fail for main table except OPS_MAIN.
        2) On UI, user should only see columns of OPS_MAIN.
9. Cube refresh:
    1) All data modifications or consolidation activities on a main table should reflect in the cube after publishing cube.
10. Data lake mapping
    1) Project Setup UI
        1.1) User should be able to select multiple main tables in the dropdown checkboxes.
        1.2) User should be able to map columns from multiple main tables.
        1.3) User should be able to add filters for multiple main tables.
        1.4) User should be able to save mappings and filters from above points and on page refresh, 
        same mappings and filters should be visible.
    2) Workflow job - Publish - move data to data lake:
        2.1) pushing data for the first time: push all the data in maintable.
        2.2) some records are updated, push those records.
        2.3) some records are deleted, push those records.
        2.4) pushing data, but there is no delta data.
        2.5) table name do not matches with the table name given in basic details.

Pending:
3. Job export and Job import - pending with Vishal Khot.


Test case completion review:
1. Load data in a source table
2. Move data from source table to a new main table - Consolidation.
3. Delete data from Load Data screen - first with new main table then the source table.
4. Create a Reference master using Master Based Normalization
5. Update or purge data in Reference master table that you created from Master Based Normalization
6. Add custom columns and same should be available during configuration across all screens of Workflow.
7. Configure and run a job with one main table with stop after every stage
8. When job is stopped at last step, then run another job with different main table. It should be in progress.
9. When second job completes, then run first job again.
